# import the necessary packages
import argparse
import json
import imutils
import cv2
import numpy as np

# This file convert the binary image generated by our semantic segmentation model to the json label in original TuSimple
# format so that we an evaluate our accuracy using TuSimple evaluation metrics.
def convert_binary_image_to_json_label():
    json_gt = [json.loads(line) for line in open('label_data.json')]

    train_file_name = set(line.strip() for line in open('train.txt').readlines())
    val_file_name = set(line.strip() for line in open('val.txt').readlines())
    test_file_name = set(line.strip() for line in open('test.txt').readlines())

    train_outputs = []
    val_outputs = []
    test_outputs = []
    for count, gt in enumerate(json_gt):
        gt_lanes = gt['lanes']
        raw_file = gt['raw_file']
        generated_file = "_".join(raw_file.split('/')[:-1]) + ".png"

        #construct the argument parse and parse the arguments
        ap = argparse.ArgumentParser()
        ap.add_argument("-i", "--home_dir", required=True,
                        help="path to the HOME_DIR")
        args = vars(ap.parse_args())

        # load the image, convert it to grayscale, blur it slightly,
        # and threshold it

        #print (args["home_dir"] )
        image = cv2.imread(args["home_dir"] + '/' + generated_file)
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        thresh = cv2.threshold(blurred, 180, 255, cv2.THRESH_BINARY)[1]

        output = {}
        output["lanes"] = [[] for _ in range(len(gt_lanes))]
        output["h_samples"] = []
        output["raw_file"] = raw_file
        for h_start in range(60, 190, 5):
            output["h_samples"].append(h_start + 5)

            slice = thresh[h_start: h_start + 10, :]

            # find contours in the thresholded image
            cnts = cv2.findContours(slice.copy(), cv2.RETR_EXTERNAL,
                                cv2.CHAIN_APPROX_SIMPLE)
            cnts = imutils.grab_contours(cnts)

            #loop over the contours
            for i in range(len(gt_lanes)):
                if i < len(cnts):
                    # compute the center of the contour
                    c = cnts[i]
                    M = cv2.moments(c)
                    if M["m00"] != 0:
                        cX = int(M["m10"] / M["m00"])
                        cY = int(M["m01"] / M["m00"])

                        # draw the contour and center of the shape on the image
                        cv2.circle(image, (cX, h_start + 5), 3, (255, 255, 255), -1)
                        output["lanes"][i].append(cX)
                    else:
                        output["lanes"][i].append(-2)
                else:
                    output["lanes"][i].append(-2)

        if generated_file in train_file_name:
            train_outputs.append(output)
        if generated_file in val_file_name:
            val_outputs.append(output)
        if generated_file in test_file_name:
            test_outputs.append(output)

    with open('train_pred.txt', 'w') as outfile:
        for output in train_outputs:
            json.dump(output, outfile)
            outfile.write("\n")
    outfile.close()

    with open('val_pred.txt', 'w') as outfile:
        for output in val_outputs:
            json.dump(output, outfile)
            outfile.write("\n")
    outfile.close()

    with open('test_pred.txt', 'w') as outfile:
        for output in test_outputs:
            json.dump(output, outfile)
            outfile.write("\n")
    outfile.close()

if __name__ == "__main__":
    convert_binary_image_to_json_label()